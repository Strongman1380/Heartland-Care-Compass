## Copy this file to .env and fill with your values
## Never commit your real secrets to version control


# Server Configuration
PORT=3000
NODE_ENV=development

# CORS (comma-separated list of allowed origins, e.g., http://localhost:8080)
# CORS_ORIGIN=http://localhost:8080

# Auth
# Generate a strong random value for production
JWT_SECRET=change-me-in-production
# Simple bootstrap admin API key to obtain JWTs
ADMIN_API_KEY=change-me

# Firebase client configuration (used in the Vite frontend)
VITE_FIREBASE_API_KEY=your_firebase_api_key
VITE_FIREBASE_AUTH_DOMAIN=your-project.firebaseapp.com
VITE_FIREBASE_PROJECT_ID=your-project-id
VITE_FIREBASE_STORAGE_BUCKET=your-project.firebasestorage.app
VITE_FIREBASE_MESSAGING_SENDER_ID=your_sender_id
VITE_FIREBASE_APP_ID=your_firebase_app_id
VITE_FIREBASE_MEASUREMENT_ID=G-XXXXXXXXXX

# ============================================================================
# AI CONFIGURATION (OpenAI)
# ============================================================================
# OpenAI API Key - Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# AI Model Selection
# Options: gpt-4o-mini (recommended, cost-effective), gpt-4o, gpt-4-turbo
OPENAI_MODEL=gpt-4o-mini
OPENAI_MODEL_STANDARD=gpt-4o-mini
OPENAI_MODEL_PREMIUM=gpt-4o

# Maximum tokens per AI request
# Lower = faster & cheaper, Higher = more detailed responses
# Recommended: 2000 for reports, 800 for summaries
OPENAI_MAX_TOKENS=2000

# AI Runtime Controls
# Cache keeps repeated prompts fast and cheaper.
AI_CACHE_TTL_SECONDS=600
AI_CACHE_MAX_ITEMS=400

# Global daily usage ceilings (all users combined)
AI_DAILY_REQUEST_LIMIT=1200
AI_DAILY_TOKEN_LIMIT=450000

# Per-client daily usage ceilings
AI_CLIENT_DAILY_REQUEST_LIMIT=250
AI_CLIENT_DAILY_TOKEN_LIMIT=125000
